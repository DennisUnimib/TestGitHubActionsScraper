name: TrovaCasa Scraper Completo

on:
  # Esecuzione automatica ogni giorno alle 6:00 UTC (7:00/8:00 in Italia)
  # Orario anticipato perché questo workflow richiede più tempo
  schedule:
    - cron: '0 6 * * *'
  
  # Permetti esecuzione manuale
  workflow_dispatch:
    inputs:
      max_pages:
        description: 'Numero massimo di pagine da scaricare (0 = tutte, consigliato max 10 per test)'
        required: false
        default: '3'
        type: string

jobs:
  scrape-complete-data:
    runs-on: ubuntu-latest
    timeout-minutes: 120  # Timeout di 2 ore per scraping completo
    
    permissions:
      contents: write  # Necessario per creare releases
    
    steps:
    - name: Checkout repository
      uses: actions/checkout@v4
    
    - name: Set up Python
      uses: actions/setup-python@v4
      with:
        python-version: '3.11'
    
    - name: Cache pip dependencies
      uses: actions/cache@v3
      with:
        path: ~/.cache/pip
        key: ${{ runner.os }}-pip-completo-${{ hashFiles('**/requirements.txt') }}
        restore-keys: |
          ${{ runner.os }}-pip-completo-
    
    - name: Install dependencies
      run: |
        python -m pip install --upgrade pip
        pip install -r requirements.txt
    
    - name: Run complete scraper
      env:
        MAX_PAGES: ${{ github.event.inputs.max_pages || '3' }}
      run: |
        echo "🚀 Avvio scraping completo con MAX_PAGES=$MAX_PAGES"
        python scraper_completo.py
    
    - name: Get CSV info and statistics
      id: file_info
      run: |
        if [ -f csv_filename.txt ]; then
          CSV_FILE=$(cat csv_filename.txt)
          echo "csv_file=$CSV_FILE" >> $GITHUB_OUTPUT
          
          # Estrai informazioni dal nome file
          TIMESTAMP=$(echo $CSV_FILE | grep -o '[0-9]\{8\}_[0-9]\{6\}' | head -1)
          ANNUNCI_COUNT=$(echo $CSV_FILE | grep -o '_[0-9]\+_annunci' | grep -o '[0-9]\+' | head -1)
          
          echo "timestamp=$TIMESTAMP" >> $GITHUB_OUTPUT
          echo "annunci_count=${ANNUNCI_COUNT:-0}" >> $GITHUB_OUTPUT
          
          # Calcola dimensione file
          if [ -f "$CSV_FILE" ]; then
            FILE_SIZE=$(du -h "$CSV_FILE" | cut -f1)
            echo "file_size=$FILE_SIZE" >> $GITHUB_OUTPUT
            
            # Conta colonne (se il file non è vuoto)
            if [ -s "$CSV_FILE" ]; then
              COLUMNS_COUNT=$(head -1 "$CSV_FILE" | tr ';' '\n' | wc -l)
              echo "columns_count=$COLUMNS_COUNT" >> $GITHUB_OUTPUT
            else
              echo "columns_count=0" >> $GITHUB_OUTPUT
            fi
          else
            echo "file_size=0B" >> $GITHUB_OUTPUT
            echo "columns_count=0" >> $GITHUB_OUTPUT
          fi
        else
          echo "❌ File CSV non trovato"
          exit 1
        fi
    
    - name: Create Release
      id: create_release
      uses: actions/create-release@v1
      env:
        GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}
      with:
        tag_name: scraping-completo-${{ steps.file_info.outputs.timestamp }}
        release_name: 🏠 TrovaCasa Milano COMPLETO - ${{ steps.file_info.outputs.timestamp }}
        body: |
          # 📊 Scraping Completo TrovaCasa Milano
          
          **📅 Data estrazione**: ${{ steps.file_info.outputs.timestamp }}  
          **🏠 Annunci processati**: ${{ steps.file_info.outputs.annunci_count }}  
          **📏 Dimensione file**: ${{ steps.file_info.outputs.file_size }}  
          **📋 Colonne dati**: ${{ steps.file_info.outputs.columns_count }}  
          **🎯 Città**: Milano  
          **🌐 Fonte**: trovacasa.it  
          
          ## 📋 Dati Inclusi
          Il file CSV contiene informazioni dettagliate per ogni annuncio:
          - 🔗 **URL** dell'annuncio
          - 💰 **Prezzo** 
          - 🏠 **Titolo** e descrizione
          - 📍 **Indirizzo**
          - 📐 **Superficie** (m²)
          - 🚪 **Numero locali**
          - 🚿 **Numero bagni**
          - ⚡ **Classe energetica**
          - 🏷️ **Tag** caratteristiche
          - 📅 **Date** di monitoraggio
          
          ## 📥 Come utilizzare
          1. Scarica il file CSV allegato
          2. Apri con Excel, Google Sheets o qualsiasi editor CSV
          3. **Separatore**: punto e virgola (;)
          4. **Encoding**: UTF-8
          
          ## 📊 Formato Dati
          ```
          _id;url;prezzo;titolo;indirizzo;superficie_m2;num_locali;num_bagni;classe_ener;tags;attivo;data_comparsa;data_aggiornamento;data_scomparsa
          ```
          
          ---
          *⚡ Scraping completo generato automaticamente da GitHub Actions*
        draft: false
        prerelease: false
    
    - name: Upload CSV to Release
      uses: actions/upload-release-asset@v1
      env:
        GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}
      with:
        upload_url: ${{ steps.create_release.outputs.upload_url }}
        asset_path: ./${{ steps.file_info.outputs.csv_file }}
        asset_name: trovacasa_milano_completo_${{ steps.file_info.outputs.timestamp }}.csv
        asset_content_type: text/csv
    
    - name: Cleanup
      run: |
        rm -f *.csv csv_filename.txt
    
    - name: Log final statistics
      run: |
        echo "✅ Scraping completo terminato con successo!"
        echo "📊 Annunci processati: ${{ steps.file_info.outputs.annunci_count }}"
        echo "📏 Dimensione file: ${{ steps.file_info.outputs.file_size }}"
        echo "🔗 Release: https://github.com/${{ github.repository }}/releases/tag/scraping-completo-${{ steps.file_info.outputs.timestamp }}"
