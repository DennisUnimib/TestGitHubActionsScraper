name: TrovaCasa Scraper Completo

on:
  # Esecuzione automatica ogni giorno alle 19:30 UTC (20:00/21:00 in Italia)
  # Orario anticipato perchÃ© questo workflow richiede piÃ¹ tempo
  schedule:
    - cron: '30 19 */2 * *'
  
  # Permetti esecuzione manuale
  workflow_dispatch:
    inputs:
      max_pages:
        description: 'Numero massimo di pagine da scaricare (0 = tutte, consigliato max 10 per test)'
        required: false
        default: '3'
        type: string

jobs:
  scrape-complete-data:
    runs-on: ubuntu-latest
    timeout-minutes: 180  # Timeout di 3 ore per scraping completo
    
    permissions:
      contents: write  # Necessario per creare releases
    
    steps:
    - name: Checkout repository
      uses: actions/checkout@v4
    
    - name: Set up Python
      uses: actions/setup-python@v4
      with:
        python-version: '3.11'
    
    - name: Cache pip dependencies
      uses: actions/cache@v3
      with:
        path: ~/.cache/pip
        key: ${{ runner.os }}-pip-completo-${{ hashFiles('**/requirements_completo.txt') }}
        restore-keys: |
          ${{ runner.os }}-pip-completo-
    
    - name: Install dependencies
      run: |
        python -m pip install --upgrade pip
        pip install -r requirements_completo.txt
    
    - name: Run complete scraper
      env:
        MAX_PAGES: ${{ github.event.inputs.max_pages || '0' }} # 0 = fare scraping su tutte le pagine.
      run: |
        echo "ğŸš€ Avvio scraping completo con MAX_PAGES=$MAX_PAGES"
        python scraper_completo.py
    
    - name: Get CSV info and statistics
      id: file_info
      run: |
        if [ -f csv_filename.txt ]; then
          CSV_FILE=$(cat csv_filename.txt)
          echo "csv_file=$CSV_FILE" >> $GITHUB_OUTPUT
          
          # Estrai informazioni dal nome file
          TIMESTAMP=$(echo $CSV_FILE | grep -o '[0-9]\{8\}_[0-9]\{6\}' | head -1)
          ANNUNCI_COUNT=$(echo $CSV_FILE | grep -o '_[0-9]\+_annunci' | grep -o '[0-9]\+' | head -1)
          
          echo "timestamp=$TIMESTAMP" >> $GITHUB_OUTPUT
          echo "annunci_count=${ANNUNCI_COUNT:-0}" >> $GITHUB_OUTPUT
          
          # Calcola dimensione file
          if [ -f "$CSV_FILE" ]; then
            FILE_SIZE=$(du -h "$CSV_FILE" | cut -f1)
            echo "file_size=$FILE_SIZE" >> $GITHUB_OUTPUT
            
            # Conta colonne (se il file non Ã¨ vuoto)
            if [ -s "$CSV_FILE" ]; then
              COLUMNS_COUNT=$(head -1 "$CSV_FILE" | tr ';' '\n' | wc -l)
              echo "columns_count=$COLUMNS_COUNT" >> $GITHUB_OUTPUT
            else
              echo "columns_count=0" >> $GITHUB_OUTPUT
            fi
          else
            echo "file_size=0B" >> $GITHUB_OUTPUT
            echo "columns_count=0" >> $GITHUB_OUTPUT
          fi
        else
          echo "âŒ File CSV non trovato"
          exit 1
        fi
    
    - name: Create Release
      id: create_release
      uses: actions/create-release@v1
      env:
        GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}
      with:
        tag_name: scraping-completo-${{ steps.file_info.outputs.timestamp }}
        release_name: ğŸ  TrovaCasa Milano COMPLETO - ${{ steps.file_info.outputs.timestamp }}
        body: |
          # ğŸ“Š Scraping Completo TrovaCasa Milano
          
          **ğŸ“… Data estrazione**: ${{ steps.file_info.outputs.timestamp }}  
          **ğŸ  Annunci processati**: ${{ steps.file_info.outputs.annunci_count }}  
          **ğŸ“ Dimensione file**: ${{ steps.file_info.outputs.file_size }}  
          **ğŸ“‹ Colonne dati**: ${{ steps.file_info.outputs.columns_count }}  
          **ğŸ¯ CittÃ **: Milano  
          **ğŸŒ Fonte**: trovacasa.it  
          
          ## ğŸ“Š Formato Dati
          ```
          _id;url;prezzo;titolo;indirizzo;superficie_m2;num_locali;num_bagni;classe_ener;tags;attivo;data_comparsa;data_aggiornamento;data_scomparsa
          ```
        draft: false
        prerelease: false
    
    - name: Upload CSV to Release
      uses: actions/upload-release-asset@v1
      env:
        GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}
      with:
        upload_url: ${{ steps.create_release.outputs.upload_url }}
        asset_path: ./${{ steps.file_info.outputs.csv_file }}
        asset_name: trovacasa_milano_completo_${{ steps.file_info.outputs.timestamp }}.csv
        asset_content_type: text/csv
    
    - name: Cleanup
      run: |
        rm -f *.csv csv_filename.txt
    
    - name: Log final statistics
      run: |
        echo "âœ… Scraping completo terminato con successo!"
        echo "ğŸ“Š Annunci processati: ${{ steps.file_info.outputs.annunci_count }}"
        echo "ğŸ“ Dimensione file: ${{ steps.file_info.outputs.file_size }}"
        echo "ğŸ”— Release: https://github.com/${{ github.repository }}/releases/tag/scraping-completo-${{ steps.file_info.outputs.timestamp }}"
