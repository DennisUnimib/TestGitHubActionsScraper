# ğŸ  TrovaCasa Milano Scraper COMPLETO

Scraper automatico avanzato per raccogliere **dati completi** degli annunci immobiliari di Milano da TrovaCasa.it.

## âœ¨ NovitÃ  Versione Completa

- ğŸ” **Estrazione dati dettagliati** per ogni annuncio
- ğŸ’° **Prezzo, superficie, locali, bagni**
- ğŸ“ **Indirizzo e titolo completi**
- âš¡ **Classe energetica** 
- ğŸ·ï¸ **Tag e caratteristiche**
- ğŸ“Š **Statistiche avanzate** nei release
- â±ï¸ **Monitoraggio temporale** per analisi storiche

## ğŸ“Š Dati Estratti

Ogni annuncio include:

| Campo | Descrizione | Esempio |
|-------|-------------|---------|
| `_id` | Codice annuncio | `12345678` |
| `url` | Link all'annuncio | `https://...` |
| `prezzo` | Prezzo dell'immobile | `â‚¬ 350.000` |
| `titolo` | Titolo annuncio | `Trilocale in Via Roma` |
| `indirizzo` | Indirizzo | `Via Roma, Milano MI` |
| `superficie_m2` | Superficie in mÂ² | `85` |
| `num_locali` | Numero locali | `3` |
| `num_bagni` | Numero bagni | `2` |
| `classe_ener` | Classe energetica | `C` |
| `tags` | Caratteristiche | `["Balcone", "Ascensore"]` |
| `data_comparsa` | Data rilevazione | `2024-12-13` |

## ğŸš€ Esecuzione

### Automatica
- **Ogni giorno alle 6:00 UTC** (7:00/8:00 in Italia)
- **Timeout**: 2 ore per completare tutto il processo

### Manuale
1. **Actions** â†’ **TrovaCasa Scraper Completo**
2. **Run workflow**
3. **Scegli numero pagine** (consigliato max 10 per test)
4. **Avvia**

## ğŸ“ˆ Performance

| Scenario | Pagine | Annunci | Tempo Stimato |
|----------|--------|---------|---------------|
| **Test** | 3 | ~150 | 8-12 minuti |
| **Medio** | 10 | ~500 | 20-30 minuti |
| **Completo** | Tutte (~100+) | ~5000+ | 1-2 ore |

## ğŸ“¥ Download Dati

I CSV sono disponibili nei **[Releases](../../releases)**:
- **Nome**: `trovacasa_milano_completo_TIMESTAMP.csv`
- **Separatore**: Punto e virgola (;)
- **Encoding**: UTF-8
- **Formato**: Pronto per Excel/Google Sheets

## âš™ï¸ Configurazione

### Parametri Workflow

```yaml
# Orario esecuzione (6:00 UTC)
schedule:
  - cron: '0 6 * * *'

# Timeout massimo (2 ore)
timeout-minutes: 120

# Pagine default per esecuzione manuale
default: '3'
```

### Limiti GitHub Actions
- âœ… **2000 minuti/mese** gratuiti
- âœ… **6 ore max** per job singolo
- âœ… **1 job giornaliero â‰ˆ 30-60 minuti** â†’ circa 30 giorni di margin

## ğŸ”§ Personalizzazioni

### Cambiare CittÃ 
```python
# In scraper_completo.py
start_url = f"{base_url}/case-in-vendita/roma"  # Roma invece di Milano
```

### Modificare Concorrenza
```python
MAX_CONCURRENT_REQUESTS = 5  # PiÃ¹ conservativo
MAX_CONCURRENT_REQUESTS = 10  # PiÃ¹ aggressivo
```

### Aggiungere Campi
```python
# Nel metodo estrai_annuncio()
piano = get_value("Piano")
anno_costruzione = get_value("Anno di costruzione")
# Aggiungi ai dati...
```

## ğŸ“Š Analisi Dati

Il CSV puÃ² essere usato per:
- ğŸ“ˆ **Analisi prezzi** per zona
- ğŸ“ **Correlazione prezzo/superficie**
- ğŸ˜ï¸ **Mappatura geografica**
- ğŸ“… **Trend temporali**
- ğŸ” **Filtering avanzato**

## âš ï¸ Considerazioni

- **Rate Limiting**: Pause automatiche per evitare blocchi
- **Robustezza**: Gestione timeout ed errori
- **Memoria**: Ottimizzato per GitHub Actions
- **Rispetto del Sito**: User-agent appropriato e ritmi sostenibili

## ğŸ†š Confronto con Versione Base

| Caratteristica | Base | Completo |
|---------------|------|----------|
| **Dati** | Solo URL | 12+ campi dettagliati |
| **Tempo** | 2-5 min | 20-120 min |
| **File** | ~50KB | ~2-10MB |
| **Analisi** | Limitata | Completa |
| **Uso memoria** | Basso | Medio |

## ğŸ”’ Privacy e LegalitÃ 

- âœ… **Solo dati pubblici**
- âœ… **Rispetto robots.txt**
- âœ… **Rate limiting appropriato**
- âœ… **Storage privato** (se repository privato)

---

*ğŸš€ Per la versione base (solo URL), vedi branch `main`*